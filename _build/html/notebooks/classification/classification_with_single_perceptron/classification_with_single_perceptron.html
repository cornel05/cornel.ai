
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" data-theme="light">

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Simple Binary Classification with Sigmoid Activation &#8212; AI Learning Labs</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "light";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-design.min.css?v=95c83b7e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/landing_page.css?v=2ed7ac62" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/date.css?v=7762d749" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/footer.css?v=7252cef9" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/font.css?v=0214559b" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=JetBrains+Mono&display=swap" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Fira+Code&display=swap" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../_static/design-tabs.js?v=f930bc37"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'notebooks/classification/classification_with_single_perceptron/classification_with_single_perceptron';</script>
    <link rel="icon" href="../../../_static/logo.png"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Regression" href="../../regression/index.html" />
    <link rel="prev" title="Classification" href="../index.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="light">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search the docs ..."
         aria-label="Search the docs ..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
<div class="bd-header__inner bd-page-width">
  <button class="pst-navbar-icon sidebar-toggle primary-toggle" aria-label="Site navigation">
    <span class="fa-solid fa-bars"></span>
  </button>
  
  
  <div class=" navbar-header-items__start">
    
      <div class="navbar-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
    
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt=""/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt=""/>`);</script>
  
  
    <p class="title logo__title">cornel.ai</p>
  
</a></div>
    
  </div>
  
  <div class=" navbar-header-items">
    
    <div class="me-auto navbar-header-items__center">
      
        <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Classification
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../regression/index.html">
    Regression
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../optimization/index.html">
    Optimization
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../computer_vision/index.html">
    Computer Vision
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../pandas/index.html">
    Pandas
  </a>
</li>

            <li class="nav-item dropdown">
                <button class="btn dropdown-toggle nav-item" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-controls="pst-nav-more-links">
                    More
                </button>
                <ul id="pst-nav-more-links" class="dropdown-menu">
                    
<li class=" ">
  <a class="nav-link dropdown-item nav-internal" href="../../python_snippets/index.html">
    Python Snippets
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://github.com/cornel05">
    GitHub: cornel05
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://cornel05.github.io/">
    cornel05.github.io
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://scikit-learn.org/">
    scikit-learn
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://pytorch.org/">
    PyTorch
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://www.tensorflow.org/">
    TensorFlow
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://pandas.pydata.org/">
    pandas
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://numpy.org/">
    NumPy
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://matplotlib.org/">
    Matplotlib
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://seaborn.pydata.org/">
    Seaborn
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://huggingface.co/">
    Hugging Face
  </a>
</li>


<li class=" ">
  <a class="nav-link dropdown-item nav-external" href="https://www.kaggle.com/">
    Kaggle
  </a>
</li>

                </ul>
            </li>
            
  </ul>
</nav></div>
      
    </div>
    
    
    <div class="navbar-header-items__end">
      
        <div class="navbar-item navbar-persistent--container">
          

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
        </div>
      
      
        <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
      
        <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cornel05/AI-Learning-Labs" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/dcornel05" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://www.linkedin.com/in/cornel-ai" title="LinkedIn" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-linkedin fa-lg" aria-hidden="true"></i>
            <span class="sr-only">LinkedIn</span></a>
        </li>
</ul></div>
      
    </div>
    
  </div>
  
  
    <div class="navbar-persistent--mobile">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script>
    </div>
  

  
    <button class="pst-navbar-icon sidebar-toggle secondary-toggle" aria-label="On this page">
      <span class="fa-solid fa-outdent"></span>
    </button>
  
</div>

    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
      <div class="sidebar-header-items__center">
        
          
          
            <div class="navbar-item">
<nav>
  <ul class="bd-navbar-elements navbar-nav">
    
<li class="nav-item current active">
  <a class="nav-link nav-internal" href="../index.html">
    Classification
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../regression/index.html">
    Regression
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../optimization/index.html">
    Optimization
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../computer_vision/index.html">
    Computer Vision
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../pandas/index.html">
    Pandas
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-internal" href="../../python_snippets/index.html">
    Python Snippets
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://github.com/cornel05">
    GitHub: cornel05
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://cornel05.github.io/">
    cornel05.github.io
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://scikit-learn.org/">
    scikit-learn
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pytorch.org/">
    PyTorch
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://www.tensorflow.org/">
    TensorFlow
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://pandas.pydata.org/">
    pandas
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://numpy.org/">
    NumPy
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://matplotlib.org/">
    Matplotlib
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://seaborn.pydata.org/">
    Seaborn
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://huggingface.co/">
    Hugging Face
  </a>
</li>


<li class="nav-item ">
  <a class="nav-link nav-external" href="https://www.kaggle.com/">
    Kaggle
  </a>
</li>

  </ul>
</nav></div>
          
        
      </div>
    
    
    
      <div class="sidebar-header-items__end">
        
          <div class="navbar-item">

<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script></div>
        
          <div class="navbar-item"><ul class="navbar-icon-links"
    aria-label="Icon Links">
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://github.com/cornel05/AI-Learning-Labs" title="GitHub" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-github fa-lg" aria-hidden="true"></i>
            <span class="sr-only">GitHub</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://x.com/dcornel05" title="Twitter" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-twitter fa-lg" aria-hidden="true"></i>
            <span class="sr-only">Twitter</span></a>
        </li>
        <li class="nav-item">
          
          
          
          
          
          
          
          
          <a href="https://www.linkedin.com/in/cornel-ai" title="LinkedIn" class="nav-link pst-navbar-icon" rel="noopener" target="_blank" data-bs-toggle="tooltip" data-bs-placement="bottom"><i class="fa-brands fa-linkedin fa-lg" aria-hidden="true"></i>
            <span class="sr-only">LinkedIn</span></a>
        </li>
</ul></div>
        
      </div>
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
<nav class="bd-docs-nav bd-links"
     aria-label="Section Navigation">
  <p class="bd-links__title" role="heading" aria-level="1">Section Navigation</p>
  <div class="bd-toc-item navbar-nav"><p aria-level="2" class="caption" role="heading"><span class="caption-text">Binary Classification</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Simple Binary Classification with Sigmoid Activation</a></li>
</ul>
</div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        
          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item">



<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../index.html" class="nav-link">Classification</a></li>
    
    <li class="breadcrumb-item active" aria-current="page">Simple...</li>
  </ul>
</nav>
</div>
      
    </div>
  
  
</div>
</div>
              
              
              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="simple-binary-classification-with-sigmoid-activation">
<h1>Simple Binary Classification with Sigmoid Activation<a class="headerlink" href="#simple-binary-classification-with-sigmoid-activation" title="Link to this heading">#</a></h1>
<section id="packages">
<h2>Packages<a class="headerlink" href="#packages" title="Link to this heading">#</a></h2>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">matplotlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">colors</span>
<span class="c1"># A function to create a dataset.</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.datasets</span><span class="w"> </span><span class="kn">import</span> <span class="n">make_blobs</span> 

<span class="c1"># Output of plotting commands is displayed inline within the Jupyter notebook.</span>
<span class="o">%</span><span class="k">matplotlib</span> inline 

<span class="c1"># Set a seed so that the results are consistent.</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><a name='1'></a></p>
</section>
<section id="single-perceptron-neural-network-with-activation-function">
<h2>1 - Single Perceptron Neural Network with Activation Function<a class="headerlink" href="#single-perceptron-neural-network-with-activation-function" title="Link to this heading">#</a></h2>
<p>You already have constructed and trained a neural network model with one <strong>perceptron</strong>. Here a similar model can be used, but with an activation function. Then a single perceptron basically works as a threshold function.</p>
<p><a name='1.1'></a></p>
<section id="neural-network-structure">
<h3>1.1 - Neural Network Structure<a class="headerlink" href="#neural-network-structure" title="Link to this heading">#</a></h3>
<p>The neural network components are shown in the following scheme:</p>
<!-- ![Neural Network Structure](images/nn_model_classification_1_layer.png){width=600px} -->
<figure class="align-default" id="nn-model-classification-1-layer">
<a class="reference internal image-reference" href="../../../_images/nn_model_classification_1_layer.png"><img alt="../../../_images/nn_model_classification_1_layer.png" src="../../../_images/nn_model_classification_1_layer.png" style="width: 600px;" />
</a>
<figcaption>
<p><span class="caption-text">Neural Network Structure</span><a class="headerlink" href="#nn-model-classification-1-layer" title="Link to this image">#</a></p>
</figcaption>
</figure>
<p>Similarly to the previous lab, the input layer contains two nodes <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span>. Weight vector <span class="math notranslate nohighlight">\(W = \begin{bmatrix} w_1 &amp; w_2\end{bmatrix}\)</span> and bias (<span class="math notranslate nohighlight">\(b\)</span>) are the parameters to be updated during the model training. First step in the forward propagation is the same as in the previous lab. For every training example <span class="math notranslate nohighlight">\(x^{(i)} = \begin{bmatrix} x_1^{(i)} &amp; x_2^{(i)}\end{bmatrix}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
z^{(i)} = w_1x_1^{(i)} + w_2x_2^{(i)} + b = Wx^{(i)} + b.
\]</div>
<p>But now you cannot take a real number <span class="math notranslate nohighlight">\(z^{(i)}\)</span> into the output as you need to perform classification. It could be done with a discrete approach: compare the result with zero, and classify as <span class="math notranslate nohighlight">\(0\)</span> (blue) if it is below zero and <span class="math notranslate nohighlight">\(1\)</span> (red) if it is above zero. Then define cost function as a percentage of incorrectly identified classes and perform backward propagation.</p>
<p>This extra step in the forward propagation is actually an application of an <strong>activation function</strong>. It would be possible to implement the discrete approach described above (with unit step function) for this problem, but it turns out that there is a continuous approach that works better and is commonly used in more complicated neural networks. So you will implement it here: single perceptron with sigmoid activation function.</p>
<p>Sigmoid activation function is defined as</p>
<div class="math notranslate nohighlight">
\[
a = \sigma\left(z\right) = \frac{1}{1+e^{-z}}.
\tag{2}
\]</div>
<p>Then a threshold value of <span class="math notranslate nohighlight">\(0.5\)</span> can be used for predictions: <span class="math notranslate nohighlight">\(1\)</span> (red) if  <span class="math notranslate nohighlight">\(a &gt; 0.5\)</span> and <span class="math notranslate nohighlight">\(0\)</span> (blue) otherwise. Putting it all together, mathematically the single perceptron neural network with sigmoid activation function can be expressed as:</p>
<div class="math notranslate nohighlight">
\[
z^{(i)} =  W x^{(i)} + b
\]</div>
<div class="math notranslate nohighlight">
\[
a^{(i)} = \sigma\left(z^{(i)}\right). \tag{3}
\]</div>
<p>If you have <span class="math notranslate nohighlight">\(m\)</span> training examples organised in the columns of (<span class="math notranslate nohighlight">\(2 \times m\)</span>) matrix <span class="math notranslate nohighlight">\(X\)</span>, you can apply the activation function element-wise. So the model can be written as:</p>
<div class="math notranslate nohighlight">
\[
Z =  W X + b
\]</div>
<div class="math notranslate nohighlight">
\[
A = \sigma\left(Z\right), \tag{4}
\]</div>
<p>where <span class="math notranslate nohighlight">\(b\)</span> is broadcasted to the vector of a size (<span class="math notranslate nohighlight">\(1 \times m\)</span>).</p>
<p>When dealing with classification problems, the most commonly used cost function is the <strong>log loss</strong>, which is described by the following equation:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}\left(W, b\right) = \frac{1}{m}\sum_{i=1}^{m} L\left(W, b\right) = \frac{1}{m}\sum_{i=1}^{m}  \large\left(\small -y^{(i)}\log\left(a^{(i)}\right) - (1-y^{(i)})\log\left(1- a^{(i)}\right)  \large  \right) \small, \tag{5}
\]</div>
<p>where <span class="math notranslate nohighlight">\(y^{(i)} \in \{0,1\}\)</span> are the original labels and <span class="math notranslate nohighlight">\(a^{(i)}\)</span> are the continuous output values of the forward propagation step (elements of array <span class="math notranslate nohighlight">\(A\)</span>).</p>
<p>You want to minimize the cost function during the training. To implement gradient descent, calculate partial derivatives using chain rule:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial w_1 } = 
\frac{1}{m}\sum_{i=1}^{m} \frac{\partial L }{ \partial a^{(i)}}
\frac{\partial a^{(i)} }{ \partial z^{(i)}}\frac{\partial z^{(i)} }{ \partial w_1}
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial w_2 } = 
\frac{1}{m}\sum_{i=1}^{m} \frac{\partial L }{ \partial a^{(i)}}
\frac{\partial a^{(i)} }{ \partial z^{(i)}}\frac{\partial z^{(i)} }{ \partial w_2}, \tag{6}
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial b } = 
\frac{1}{m}\sum_{i=1}^{m} \frac{\partial L }{ \partial a^{(i)}}
\frac{\partial a^{(i)} }{ \partial z^{(i)}}\frac{\partial z^{(i)} }{ \partial b}.
\]</div>
<p>As discussed in the videos, <span class="math notranslate nohighlight">\(\frac{\partial L }{ \partial a^{(i)}}
\frac{\partial a^{(i)} }{ \partial z^{(i)}} = \left(a^{(i)} - y^{(i)}\right)\)</span>, <span class="math notranslate nohighlight">\(\frac{\partial z^{(i)}}{ \partial w_1} = x_1^{(i)}\)</span>, <span class="math notranslate nohighlight">\(\frac{\partial z^{(i)}}{ \partial w_2} = x_2^{(i)}\)</span> and <span class="math notranslate nohighlight">\(\frac{\partial z^{(i)}}{ \partial b} = 1\)</span>. Then <span class="math notranslate nohighlight">\((6)\)</span> can be rewritten as:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial w_1 } = 
\frac{1}{m}\sum_{i=1}^{m} \left(a^{(i)} - y^{(i)}\right)x_1^{(i)}
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial w_2 } = 
\frac{1}{m}\sum_{i=1}^{m} \left(a^{(i)} - y^{(i)}\right)x_2^{(i)}, \tag{7}
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial b } = 
\frac{1}{m}\sum_{i=1}^{m} \left(a^{(i)} - y^{(i)}\right).
\]</div>
<p>Note that the obtained expressions <span class="math notranslate nohighlight">\((7)\)</span> are exactly the same as in the section <span class="math notranslate nohighlight">\(3.2\)</span> of the previous lab, when multiple linear regression model was discussed. Thus, they can be rewritten in a matrix form:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial W } = 
\begin{bmatrix} \frac{\partial \mathcal{L} }{ \partial w_1 } &amp; 
\frac{\partial \mathcal{L} }{ \partial w_2 }\end{bmatrix} = \frac{1}{m}\left(A - Y\right)X^T
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial b } = \frac{1}{m}\left(A - Y\right)\mathbf{1}. \tag{8}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\left(A - Y\right)\)</span> is an array of a shape (<span class="math notranslate nohighlight">\(1 \times m\)</span>), <span class="math notranslate nohighlight">\(X^T\)</span> is an array of a shape (<span class="math notranslate nohighlight">\(m \times 2\)</span>) and <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> is just a (<span class="math notranslate nohighlight">\(m \times 1\)</span>) vector of ones.</p>
<p>Then you can update the parameters:</p>
<div class="math notranslate nohighlight">
\[
W = W - \alpha \frac{\partial \mathcal{L} }{ \partial W }
\]</div>
<div class="math notranslate nohighlight">
\[
b = b - \alpha \frac{\partial \mathcal{L} }{ \partial b }, \tag{9}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha\)</span> is the learning rate. Repeat the process in a loop until the cost function stops decreasing.</p>
<p>Finally, the predictions for some example <span class="math notranslate nohighlight">\(x\)</span> can be made taking the output <span class="math notranslate nohighlight">\(a\)</span> and calculating <span class="math notranslate nohighlight">\(\hat{y}\)</span> as</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\hat{y} = 
\begin{cases}
1, &amp; \text{if } a \ge 0.5 \\
0, &amp; \text{otherwise}
\end{cases}
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
\tag{10}
\]</div>
<p><a name='1.2'></a></p>
</section>
<section id="dataset">
<h3>- Dataset<a class="headerlink" href="#dataset" title="Link to this heading">#</a></h3>
<p>Letâ€™s get the dataset you will work on. The following code will create <span class="math notranslate nohighlight">\(m=30\)</span> data points <span class="math notranslate nohighlight">\((x_1, x_2)\)</span>, where <span class="math notranslate nohighlight">\(x_1, x_2 \in \{0,1\}\)</span> and save them in the <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> array <code class="docutils literal notranslate"><span class="pre">X</span></code> of a shape <span class="math notranslate nohighlight">\((2 \times m)\)</span> (in the columns of the array). The labels (<span class="math notranslate nohighlight">\(0\)</span>: blue, <span class="math notranslate nohighlight">\(1\)</span>: red) will be calculated so that <span class="math notranslate nohighlight">\(y = 1\)</span> if <span class="math notranslate nohighlight">\(x_1 = 0\)</span> and <span class="math notranslate nohighlight">\(x_2 = 1\)</span>, in the rest of the cases <span class="math notranslate nohighlight">\(y=0\)</span>. The labels will be saved in the array <code class="docutils literal notranslate"><span class="pre">Y</span></code> of a shape <span class="math notranslate nohighlight">\((1 \times m)\)</span>.</p>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">m</span> <span class="o">=</span> <span class="mi">30</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">m</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training dataset X containing (x1, x2) coordinates in the columns:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training dataset Y containing labels of two classes (0: blue, 1: red)&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>

<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;The shape of X is: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;The shape of Y is: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span> <span class="p">(</span><span class="s1">&#39;I have m = </span><span class="si">%d</span><span class="s1"> training examples!&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training dataset X containing (x1, x2) coordinates in the columns:
[[0 0 1 1 0 0 0 1 1 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0]
 [0 1 0 1 1 0 1 0 0 1 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0]]
Training dataset Y containing labels of two classes (0: blue, 1: red)
[[0 1 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1 0 0]]
The shape of X is: (2, 30)
The shape of Y is: (1, 30)
I have m = 30 training examples!
</pre></div>
</div>
</div>
</details>
</div>
<p><a name='1.3'></a></p>
</section>
<section id="define-activation-function">
<h3>- Define Activation Function<a class="headerlink" href="#define-activation-function" title="Link to this heading">#</a></h3>
<p>The sigmoid function <span class="math notranslate nohighlight">\((2)\)</span> for a variable <span class="math notranslate nohighlight">\(z\)</span> can be defined with the following code:</p>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
    
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sigmoid(-2) = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sigmoid(0) = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="mi">0</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;sigmoid(3.5) = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="mf">3.5</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sigmoid(-2) = 0.11920292202211755
sigmoid(0) = 0.5
sigmoid(3.5) = 0.9706877692486436
</pre></div>
</div>
</div>
</details>
</div>
<p>It can be applied to a <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> array element by element:</p>
<div class="cell tag_graded tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">])))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.11920292 0.5        0.97068777]
</pre></div>
</div>
</div>
</details>
</div>
<p><a name='2'></a></p>
</section>
</section>
<section id="implementation-of-the-neural-network-model">
<h2>2 - Implementation of the Neural Network Model<a class="headerlink" href="#implementation-of-the-neural-network-model" title="Link to this heading">#</a></h2>
<p>Implementation of the described neural network will be very similar to the <code class="docutils literal notranslate"><span class="pre">regression_with_single_perceptron</span></code> lab. The differences will be only in the functions <code class="docutils literal notranslate"><span class="pre">forward_propagation</span></code> and <code class="docutils literal notranslate"><span class="pre">compute_cost</span></code>!</p>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Arguments:</span>
<span class="sd">    X -- input dataset of shape (input size, number of examples)</span>
<span class="sd">    Y -- labels of shape (output size, number of examples)</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    n_x -- the size of the input layer</span>
<span class="sd">    n_y -- the size of the output layer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">n_x</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>

<span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span> <span class="o">=</span> <span class="n">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The size of the input layer is: n_x = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_x</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The size of the output layer is: n_y = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">n_y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The size of the input layer is: n_x = 2
The size of the output layer is: n_y = 1
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">initialize_parameters</span><span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns:</span>
<span class="sd">    params -- python dictionary containing your parameters:</span>
<span class="sd">                    W -- weight matrix of shape (n_y, n_x)</span>
<span class="sd">                    b -- bias value set as a vector of shape (n_y, 1)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">n_y</span><span class="p">,</span> <span class="n">n_x</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.01</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;W&quot;</span><span class="p">:</span> <span class="n">W</span><span class="p">,</span>
                  <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">b</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">parameters</span>

<span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W = [[-0.00768836 -0.00230031]]
b = [[0.]]
</pre></div>
</div>
</div>
</details>
</div>
<p>Implement <code class="docutils literal notranslate"><span class="pre">forward_propagation()</span></code> following the equation <span class="math notranslate nohighlight">\((4)\)</span>:
$<span class="math notranslate nohighlight">\(
Z =  W X + b
\)</span><span class="math notranslate nohighlight">\(
\)</span><span class="math notranslate nohighlight">\(
A = \sigma\left(Z\right).
\)</span>$</p>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Argument:</span>
<span class="sd">    X -- input data of size (n_x, m)</span>
<span class="sd">    parameters -- python dictionary containing your parameters (output of initialization function)</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    A -- The output</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span>
    
    <span class="c1"># Forward Propagation to calculate Z.</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">W</span> <span class="o">@</span> <span class="n">X</span> <span class="o">+</span> <span class="n">b</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">Z</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">A</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Output vector A:&quot;</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output vector A: [[0.5        0.49942492 0.49807792 0.49750285 0.49942492 0.5
  0.49942492 0.49807792 0.49807792 0.49750285 0.49942492 0.49807792
  0.49807792 0.49750285 0.5        0.49750285 0.49807792 0.49942492
  0.49942492 0.49942492 0.49942492 0.49807792 0.49750285 0.5
  0.5        0.49942492 0.49750285 0.49942492 0.5        0.5       ]]
</pre></div>
</div>
</div>
</details>
</div>
<p>Your weights were just initialized with some random values, so the model has not been trained yet.</p>
<p>Define a cost function <span class="math notranslate nohighlight">\((5)\)</span> which will be used to train the model:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}\left(W, b\right)  = \frac{1}{m}\sum_{i=1}^{m}  \large\left(\small -y^{(i)}\log\left(a^{(i)}\right) - (1-y^{(i)})\log\left(1- a^{(i)}\right)  \large  \right) \small. \tag{5}
\]</div>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">compute_cost</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the log loss cost function</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    A -- The output of the neural network of shape (n_y, number of examples)</span>
<span class="sd">    Y -- &quot;true&quot; labels vector of shape (n_y, number of examples)</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    cost -- log loss</span>
<span class="sd">    </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Number of examples.</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="c1"># Compute the cost function.</span>
    <span class="n">logprobs</span> <span class="o">=</span> <span class="o">-</span> <span class="p">(</span><span class="n">Y</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">A</span><span class="p">))</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">Y</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">A</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">logprobs</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">cost</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cost = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">compute_cost</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">Y</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cost = 0.6916391611507908
</pre></div>
</div>
</div>
</details>
</div>
<p>Calculate partial derivatives as shown in <span class="math notranslate nohighlight">\((8)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial W } = \frac{1}{m}\left(A - Y\right)X^T
\]</div>
<div class="math notranslate nohighlight">
\[
\frac{\partial \mathcal{L} }{ \partial b } = \frac{1}{m}\left(A - Y\right)\mathbf{1}.
\]</div>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">backward_propagation</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements the backward propagation, calculating gradients</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    A -- the output of the neural network of shape (n_y, number of examples)</span>
<span class="sd">    X -- input data of shape (n_x, number of examples)</span>
<span class="sd">    Y -- &quot;true&quot; labels vector of shape (n_y, number of examples)</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    grads -- python dictionary containing gradients with respect to different parameters</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="c1"># Backward propagation: calculate partial derivatives denoted as dW, db for simplicity. </span>
    <span class="n">dZ</span> <span class="o">=</span> <span class="n">A</span> <span class="o">-</span> <span class="n">Y</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="p">(</span><span class="n">dZ</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
    <span class="n">db</span> <span class="o">=</span> <span class="mi">1</span><span class="o">/</span><span class="n">m</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dZ</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
    <span class="n">grads</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dW&quot;</span><span class="p">:</span> <span class="n">dW</span><span class="p">,</span>
             <span class="s2">&quot;db&quot;</span><span class="p">:</span> <span class="n">db</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">grads</span>

<span class="n">grads</span> <span class="o">=</span> <span class="n">backward_propagation</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;dW = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="s2">&quot;dW&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;db = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">grads</span><span class="p">[</span><span class="s2">&quot;db&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>dW = [[ 0.21571875 -0.06735779]]
db = [[0.16552706]]
</pre></div>
</div>
</div>
</details>
</div>
<p>Update parameters as shown in <span class="math notranslate nohighlight">\((9)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
W = W - \alpha \frac{\partial \mathcal{L} }{ \partial W }
\]</div>
<div class="math notranslate nohighlight">
\[
b = b - \alpha \frac{\partial \mathcal{L} }{ \partial b }.
\]</div>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">update_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Updates parameters using the gradient descent update rule</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    parameters -- python dictionary containing parameters </span>
<span class="sd">    grads -- python dictionary containing gradients </span>
<span class="sd">    learning_rate -- learning rate parameter for gradient descent</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    parameters -- python dictionary containing updated parameters </span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Retrieve each parameter from the dictionary &quot;parameters&quot;.</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span>
    
    <span class="c1"># Retrieve each gradient from the dictionary &quot;grads&quot;.</span>
    <span class="n">dW</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&quot;dW&quot;</span><span class="p">]</span>
    <span class="n">db</span> <span class="o">=</span> <span class="n">grads</span><span class="p">[</span><span class="s2">&quot;db&quot;</span><span class="p">]</span>
    
    <span class="c1"># Update rule for each parameter.</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">W</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">dW</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">b</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="n">db</span>
    
    <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;W&quot;</span><span class="p">:</span> <span class="n">W</span><span class="p">,</span>
                  <span class="s2">&quot;b&quot;</span><span class="p">:</span> <span class="n">b</span><span class="p">}</span>
    
    <span class="k">return</span> <span class="n">parameters</span>

<span class="n">parameters_updated</span> <span class="o">=</span> <span class="n">update_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W updated = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters_updated</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b updated = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters_updated</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>W updated = [[-0.26655087  0.07852904]]
b updated = [[-0.19863247]]
</pre></div>
</div>
</div>
</details>
</div>
<p>Build your neural network model in <code class="docutils literal notranslate"><span class="pre">nn_model()</span></code>.</p>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Arguments:</span>
<span class="sd">    X -- dataset of shape (n_x, number of examples)</span>
<span class="sd">    Y -- labels of shape (n_y, number of examples)</span>
<span class="sd">    num_iterations -- number of iterations in the loop</span>
<span class="sd">    learning_rate -- learning rate parameter for gradient descent</span>
<span class="sd">    print_cost -- if True, print the cost every iteration</span>
<span class="sd">    </span>
<span class="sd">    Returns:</span>
<span class="sd">    parameters -- parameters learnt by the model. They can then be used to make predictions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="n">n_x</span> <span class="o">=</span> <span class="n">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">n_y</span> <span class="o">=</span> <span class="n">layer_sizes</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
    
    <span class="n">parameters</span> <span class="o">=</span> <span class="n">initialize_parameters</span><span class="p">(</span><span class="n">n_x</span><span class="p">,</span> <span class="n">n_y</span><span class="p">)</span>
    
    <span class="c1"># Loop</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">):</span>
         
        <span class="c1"># Forward propagation. Inputs: &quot;X, parameters&quot;. Outputs: &quot;A&quot;.</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
        
        <span class="c1"># Cost function. Inputs: &quot;A, Y&quot;. Outputs: &quot;cost&quot;.</span>
        <span class="n">cost</span> <span class="o">=</span> <span class="n">compute_cost</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
        
        <span class="c1"># Backpropagation. Inputs: &quot;A, X, Y&quot;. Outputs: &quot;grads&quot;.</span>
        <span class="n">grads</span> <span class="o">=</span> <span class="n">backward_propagation</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    
        <span class="c1"># Gradient descent parameter update. Inputs: &quot;parameters, grads, learning_rate&quot;. Outputs: &quot;parameters&quot;.</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="n">update_parameters</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">grads</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">)</span>
        
        <span class="c1"># Print the cost every iteration.</span>
        <span class="k">if</span> <span class="n">print_cost</span><span class="p">:</span>
            <span class="nb">print</span> <span class="p">(</span><span class="s2">&quot;Cost after iteration </span><span class="si">%i</span><span class="s2">: </span><span class="si">%f</span><span class="s2">&quot;</span> <span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">cost</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">parameters</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">parameters</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.2</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 0: 0.693480
Cost after iteration 1: 0.608586
Cost after iteration 2: 0.554475
Cost after iteration 3: 0.513124
Cost after iteration 4: 0.478828
Cost after iteration 5: 0.449395
Cost after iteration 6: 0.423719
Cost after iteration 7: 0.401089
Cost after iteration 8: 0.380986
Cost after iteration 9: 0.363002
Cost after iteration 10: 0.346813
Cost after iteration 11: 0.332152
Cost after iteration 12: 0.318805
Cost after iteration 13: 0.306594
Cost after iteration 14: 0.295369
Cost after iteration 15: 0.285010
Cost after iteration 16: 0.275412
Cost after iteration 17: 0.266489
Cost after iteration 18: 0.258167
Cost after iteration 19: 0.250382
Cost after iteration 20: 0.243080
Cost after iteration 21: 0.236215
Cost after iteration 22: 0.229745
Cost after iteration 23: 0.223634
Cost after iteration 24: 0.217853
Cost after iteration 25: 0.212372
Cost after iteration 26: 0.207168
Cost after iteration 27: 0.202219
Cost after iteration 28: 0.197505
Cost after iteration 29: 0.193009
Cost after iteration 30: 0.188716
Cost after iteration 31: 0.184611
Cost after iteration 32: 0.180682
Cost after iteration 33: 0.176917
Cost after iteration 34: 0.173306
Cost after iteration 35: 0.169839
Cost after iteration 36: 0.166507
Cost after iteration 37: 0.163303
Cost after iteration 38: 0.160218
Cost after iteration 39: 0.157246
Cost after iteration 40: 0.154382
Cost after iteration 41: 0.151618
Cost after iteration 42: 0.148950
Cost after iteration 43: 0.146373
Cost after iteration 44: 0.143881
Cost after iteration 45: 0.141471
Cost after iteration 46: 0.139139
Cost after iteration 47: 0.136881
Cost after iteration 48: 0.134694
Cost after iteration 49: 0.132574
Cost after iteration 50: 0.130517
Cost after iteration 51: 0.128522
Cost after iteration 52: 0.126586
Cost after iteration 53: 0.124705
Cost after iteration 54: 0.122878
Cost after iteration 55: 0.121102
Cost after iteration 56: 0.119375
Cost after iteration 57: 0.117696
Cost after iteration 58: 0.116062
Cost after iteration 59: 0.114471
Cost after iteration 60: 0.112922
Cost after iteration 61: 0.111413
Cost after iteration 62: 0.109942
Cost after iteration 63: 0.108509
Cost after iteration 64: 0.107111
Cost after iteration 65: 0.105748
Cost after iteration 66: 0.104418
Cost after iteration 67: 0.103120
Cost after iteration 68: 0.101853
Cost after iteration 69: 0.100616
Cost after iteration 70: 0.099407
Cost after iteration 71: 0.098227
Cost after iteration 72: 0.097073
Cost after iteration 73: 0.095945
Cost after iteration 74: 0.094842
Cost after iteration 75: 0.093763
Cost after iteration 76: 0.092708
Cost after iteration 77: 0.091675
Cost after iteration 78: 0.090665
Cost after iteration 79: 0.089676
Cost after iteration 80: 0.088707
Cost after iteration 81: 0.087759
Cost after iteration 82: 0.086830
Cost after iteration 83: 0.085920
Cost after iteration 84: 0.085028
Cost after iteration 85: 0.084154
Cost after iteration 86: 0.083297
Cost after iteration 87: 0.082457
Cost after iteration 88: 0.081633
Cost after iteration 89: 0.080824
Cost after iteration 90: 0.080032
Cost after iteration 91: 0.079254
Cost after iteration 92: 0.078490
Cost after iteration 93: 0.077741
Cost after iteration 94: 0.077005
Cost after iteration 95: 0.076283
Cost after iteration 96: 0.075574
Cost after iteration 97: 0.074877
Cost after iteration 98: 0.074193
Cost after iteration 99: 0.073521
Cost after iteration 100: 0.072860
Cost after iteration 101: 0.072211
Cost after iteration 102: 0.071573
Cost after iteration 103: 0.070946
Cost after iteration 104: 0.070330
Cost after iteration 105: 0.069723
Cost after iteration 106: 0.069127
Cost after iteration 107: 0.068541
Cost after iteration 108: 0.067964
Cost after iteration 109: 0.067396
Cost after iteration 110: 0.066838
Cost after iteration 111: 0.066288
Cost after iteration 112: 0.065748
Cost after iteration 113: 0.065215
Cost after iteration 114: 0.064691
Cost after iteration 115: 0.064175
Cost after iteration 116: 0.063667
Cost after iteration 117: 0.063167
Cost after iteration 118: 0.062675
Cost after iteration 119: 0.062189
Cost after iteration 120: 0.061711
Cost after iteration 121: 0.061240
Cost after iteration 122: 0.060777
Cost after iteration 123: 0.060319
Cost after iteration 124: 0.059869
Cost after iteration 125: 0.059425
Cost after iteration 126: 0.058987
Cost after iteration 127: 0.058556
Cost after iteration 128: 0.058130
Cost after iteration 129: 0.057711
Cost after iteration 130: 0.057297
Cost after iteration 131: 0.056889
Cost after iteration 132: 0.056487
Cost after iteration 133: 0.056091
Cost after iteration 134: 0.055699
Cost after iteration 135: 0.055313
Cost after iteration 136: 0.054932
Cost after iteration 137: 0.054556
Cost after iteration 138: 0.054186
Cost after iteration 139: 0.053820
Cost after iteration 140: 0.053458
Cost after iteration 141: 0.053102
Cost after iteration 142: 0.052750
Cost after iteration 143: 0.052403
Cost after iteration 144: 0.052060
Cost after iteration 145: 0.051721
Cost after iteration 146: 0.051387
Cost after iteration 147: 0.051057
Cost after iteration 148: 0.050731
Cost after iteration 149: 0.050409
Cost after iteration 150: 0.050091
Cost after iteration 151: 0.049776
Cost after iteration 152: 0.049466
Cost after iteration 153: 0.049160
Cost after iteration 154: 0.048857
Cost after iteration 155: 0.048557
Cost after iteration 156: 0.048262
Cost after iteration 157: 0.047969
Cost after iteration 158: 0.047681
Cost after iteration 159: 0.047395
Cost after iteration 160: 0.047113
Cost after iteration 161: 0.046834
Cost after iteration 162: 0.046559
Cost after iteration 163: 0.046286
Cost after iteration 164: 0.046017
Cost after iteration 165: 0.045750
Cost after iteration 166: 0.045487
Cost after iteration 167: 0.045227
Cost after iteration 168: 0.044969
Cost after iteration 169: 0.044714
Cost after iteration 170: 0.044463
Cost after iteration 171: 0.044213
Cost after iteration 172: 0.043967
Cost after iteration 173: 0.043723
Cost after iteration 174: 0.043482
Cost after iteration 175: 0.043244
Cost after iteration 176: 0.043008
Cost after iteration 177: 0.042774
Cost after iteration 178: 0.042543
Cost after iteration 179: 0.042315
Cost after iteration 180: 0.042089
Cost after iteration 181: 0.041865
Cost after iteration 182: 0.041643
Cost after iteration 183: 0.041424
Cost after iteration 184: 0.041207
Cost after iteration 185: 0.040992
Cost after iteration 186: 0.040780
Cost after iteration 187: 0.040569
Cost after iteration 188: 0.040361
Cost after iteration 189: 0.040155
Cost after iteration 190: 0.039950
Cost after iteration 191: 0.039748
Cost after iteration 192: 0.039548
Cost after iteration 193: 0.039350
Cost after iteration 194: 0.039154
Cost after iteration 195: 0.038959
Cost after iteration 196: 0.038767
Cost after iteration 197: 0.038576
Cost after iteration 198: 0.038387
Cost after iteration 199: 0.038200
Cost after iteration 200: 0.038015
Cost after iteration 201: 0.037832
Cost after iteration 202: 0.037650
Cost after iteration 203: 0.037470
Cost after iteration 204: 0.037291
Cost after iteration 205: 0.037115
Cost after iteration 206: 0.036940
Cost after iteration 207: 0.036766
Cost after iteration 208: 0.036594
Cost after iteration 209: 0.036424
Cost after iteration 210: 0.036255
Cost after iteration 211: 0.036088
Cost after iteration 212: 0.035922
Cost after iteration 213: 0.035758
Cost after iteration 214: 0.035595
Cost after iteration 215: 0.035434
Cost after iteration 216: 0.035274
Cost after iteration 217: 0.035116
Cost after iteration 218: 0.034958
Cost after iteration 219: 0.034803
Cost after iteration 220: 0.034648
Cost after iteration 221: 0.034495
Cost after iteration 222: 0.034344
Cost after iteration 223: 0.034193
Cost after iteration 224: 0.034044
Cost after iteration 225: 0.033896
Cost after iteration 226: 0.033750
Cost after iteration 227: 0.033604
Cost after iteration 228: 0.033460
Cost after iteration 229: 0.033317
Cost after iteration 230: 0.033176
Cost after iteration 231: 0.033035
Cost after iteration 232: 0.032896
Cost after iteration 233: 0.032757
Cost after iteration 234: 0.032620
Cost after iteration 235: 0.032484
Cost after iteration 236: 0.032349
Cost after iteration 237: 0.032216
Cost after iteration 238: 0.032083
Cost after iteration 239: 0.031951
Cost after iteration 240: 0.031821
Cost after iteration 241: 0.031691
Cost after iteration 242: 0.031563
Cost after iteration 243: 0.031435
Cost after iteration 244: 0.031309
Cost after iteration 245: 0.031183
Cost after iteration 246: 0.031059
Cost after iteration 247: 0.030935
Cost after iteration 248: 0.030813
Cost after iteration 249: 0.030691
Cost after iteration 250: 0.030571
Cost after iteration 251: 0.030451
Cost after iteration 252: 0.030332
Cost after iteration 253: 0.030214
Cost after iteration 254: 0.030097
Cost after iteration 255: 0.029981
Cost after iteration 256: 0.029866
Cost after iteration 257: 0.029752
Cost after iteration 258: 0.029638
Cost after iteration 259: 0.029525
Cost after iteration 260: 0.029414
Cost after iteration 261: 0.029303
Cost after iteration 262: 0.029192
Cost after iteration 263: 0.029083
Cost after iteration 264: 0.028974
Cost after iteration 265: 0.028867
Cost after iteration 266: 0.028760
Cost after iteration 267: 0.028654
Cost after iteration 268: 0.028548
Cost after iteration 269: 0.028443
Cost after iteration 270: 0.028340
Cost after iteration 271: 0.028236
Cost after iteration 272: 0.028134
Cost after iteration 273: 0.028032
Cost after iteration 274: 0.027931
Cost after iteration 275: 0.027831
Cost after iteration 276: 0.027731
Cost after iteration 277: 0.027633
Cost after iteration 278: 0.027534
Cost after iteration 279: 0.027437
Cost after iteration 280: 0.027340
Cost after iteration 281: 0.027244
Cost after iteration 282: 0.027148
Cost after iteration 283: 0.027054
Cost after iteration 284: 0.026959
Cost after iteration 285: 0.026866
Cost after iteration 286: 0.026773
Cost after iteration 287: 0.026681
Cost after iteration 288: 0.026589
Cost after iteration 289: 0.026498
Cost after iteration 290: 0.026408
Cost after iteration 291: 0.026318
Cost after iteration 292: 0.026229
Cost after iteration 293: 0.026140
Cost after iteration 294: 0.026052
Cost after iteration 295: 0.025965
Cost after iteration 296: 0.025878
Cost after iteration 297: 0.025792
Cost after iteration 298: 0.025706
Cost after iteration 299: 0.025621
Cost after iteration 300: 0.025536
Cost after iteration 301: 0.025452
Cost after iteration 302: 0.025368
Cost after iteration 303: 0.025285
Cost after iteration 304: 0.025203
Cost after iteration 305: 0.025121
Cost after iteration 306: 0.025040
Cost after iteration 307: 0.024959
Cost after iteration 308: 0.024878
Cost after iteration 309: 0.024799
Cost after iteration 310: 0.024719
Cost after iteration 311: 0.024640
Cost after iteration 312: 0.024562
Cost after iteration 313: 0.024484
Cost after iteration 314: 0.024407
Cost after iteration 315: 0.024330
Cost after iteration 316: 0.024253
Cost after iteration 317: 0.024178
Cost after iteration 318: 0.024102
Cost after iteration 319: 0.024027
Cost after iteration 320: 0.023952
Cost after iteration 321: 0.023878
Cost after iteration 322: 0.023805
Cost after iteration 323: 0.023732
Cost after iteration 324: 0.023659
Cost after iteration 325: 0.023586
Cost after iteration 326: 0.023515
Cost after iteration 327: 0.023443
Cost after iteration 328: 0.023372
Cost after iteration 329: 0.023301
Cost after iteration 330: 0.023231
Cost after iteration 331: 0.023161
Cost after iteration 332: 0.023092
Cost after iteration 333: 0.023023
Cost after iteration 334: 0.022955
Cost after iteration 335: 0.022886
Cost after iteration 336: 0.022819
Cost after iteration 337: 0.022751
Cost after iteration 338: 0.022684
Cost after iteration 339: 0.022618
Cost after iteration 340: 0.022552
Cost after iteration 341: 0.022486
Cost after iteration 342: 0.022420
Cost after iteration 343: 0.022355
Cost after iteration 344: 0.022291
Cost after iteration 345: 0.022226
Cost after iteration 346: 0.022162
Cost after iteration 347: 0.022099
Cost after iteration 348: 0.022036
Cost after iteration 349: 0.021973
Cost after iteration 350: 0.021910
Cost after iteration 351: 0.021848
Cost after iteration 352: 0.021786
Cost after iteration 353: 0.021725
Cost after iteration 354: 0.021664
Cost after iteration 355: 0.021603
Cost after iteration 356: 0.021542
Cost after iteration 357: 0.021482
Cost after iteration 358: 0.021422
Cost after iteration 359: 0.021363
Cost after iteration 360: 0.021304
Cost after iteration 361: 0.021245
Cost after iteration 362: 0.021186
Cost after iteration 363: 0.021128
Cost after iteration 364: 0.021070
Cost after iteration 365: 0.021013
Cost after iteration 366: 0.020956
Cost after iteration 367: 0.020899
Cost after iteration 368: 0.020842
Cost after iteration 369: 0.020786
Cost after iteration 370: 0.020730
Cost after iteration 371: 0.020674
Cost after iteration 372: 0.020618
Cost after iteration 373: 0.020563
Cost after iteration 374: 0.020508
Cost after iteration 375: 0.020454
Cost after iteration 376: 0.020400
Cost after iteration 377: 0.020346
Cost after iteration 378: 0.020292
Cost after iteration 379: 0.020238
Cost after iteration 380: 0.020185
Cost after iteration 381: 0.020132
Cost after iteration 382: 0.020080
Cost after iteration 383: 0.020028
Cost after iteration 384: 0.019975
Cost after iteration 385: 0.019924
Cost after iteration 386: 0.019872
Cost after iteration 387: 0.019821
Cost after iteration 388: 0.019770
Cost after iteration 389: 0.019719
Cost after iteration 390: 0.019669
Cost after iteration 391: 0.019618
Cost after iteration 392: 0.019568
Cost after iteration 393: 0.019519
Cost after iteration 394: 0.019469
Cost after iteration 395: 0.019420
Cost after iteration 396: 0.019371
Cost after iteration 397: 0.019322
Cost after iteration 398: 0.019274
Cost after iteration 399: 0.019225
Cost after iteration 400: 0.019177
Cost after iteration 401: 0.019129
Cost after iteration 402: 0.019082
Cost after iteration 403: 0.019035
Cost after iteration 404: 0.018988
Cost after iteration 405: 0.018941
Cost after iteration 406: 0.018894
Cost after iteration 407: 0.018848
Cost after iteration 408: 0.018801
Cost after iteration 409: 0.018755
Cost after iteration 410: 0.018710
Cost after iteration 411: 0.018664
Cost after iteration 412: 0.018619
Cost after iteration 413: 0.018574
Cost after iteration 414: 0.018529
Cost after iteration 415: 0.018484
Cost after iteration 416: 0.018440
Cost after iteration 417: 0.018396
Cost after iteration 418: 0.018352
Cost after iteration 419: 0.018308
Cost after iteration 420: 0.018264
Cost after iteration 421: 0.018221
Cost after iteration 422: 0.018178
Cost after iteration 423: 0.018135
Cost after iteration 424: 0.018092
Cost after iteration 425: 0.018049
Cost after iteration 426: 0.018007
Cost after iteration 427: 0.017965
Cost after iteration 428: 0.017923
Cost after iteration 429: 0.017881
Cost after iteration 430: 0.017839
Cost after iteration 431: 0.017798
Cost after iteration 432: 0.017756
Cost after iteration 433: 0.017715
Cost after iteration 434: 0.017675
Cost after iteration 435: 0.017634
Cost after iteration 436: 0.017593
Cost after iteration 437: 0.017553
Cost after iteration 438: 0.017513
Cost after iteration 439: 0.017473
Cost after iteration 440: 0.017433
Cost after iteration 441: 0.017394
Cost after iteration 442: 0.017354
Cost after iteration 443: 0.017315
Cost after iteration 444: 0.017276
Cost after iteration 445: 0.017237
Cost after iteration 446: 0.017198
Cost after iteration 447: 0.017160
Cost after iteration 448: 0.017121
Cost after iteration 449: 0.017083
Cost after iteration 450: 0.017045
Cost after iteration 451: 0.017007
Cost after iteration 452: 0.016970
Cost after iteration 453: 0.016932
Cost after iteration 454: 0.016895
Cost after iteration 455: 0.016858
Cost after iteration 456: 0.016821
Cost after iteration 457: 0.016784
Cost after iteration 458: 0.016747
Cost after iteration 459: 0.016710
Cost after iteration 460: 0.016674
Cost after iteration 461: 0.016638
Cost after iteration 462: 0.016602
Cost after iteration 463: 0.016566
Cost after iteration 464: 0.016530
Cost after iteration 465: 0.016494
Cost after iteration 466: 0.016459
Cost after iteration 467: 0.016423
Cost after iteration 468: 0.016388
Cost after iteration 469: 0.016353
Cost after iteration 470: 0.016318
Cost after iteration 471: 0.016284
Cost after iteration 472: 0.016249
Cost after iteration 473: 0.016215
Cost after iteration 474: 0.016180
Cost after iteration 475: 0.016146
Cost after iteration 476: 0.016112
Cost after iteration 477: 0.016078
Cost after iteration 478: 0.016045
Cost after iteration 479: 0.016011
Cost after iteration 480: 0.015977
Cost after iteration 481: 0.015944
Cost after iteration 482: 0.015911
Cost after iteration 483: 0.015878
Cost after iteration 484: 0.015845
Cost after iteration 485: 0.015812
Cost after iteration 486: 0.015780
Cost after iteration 487: 0.015747
Cost after iteration 488: 0.015715
Cost after iteration 489: 0.015683
Cost after iteration 490: 0.015650
Cost after iteration 491: 0.015618
Cost after iteration 492: 0.015587
Cost after iteration 493: 0.015555
Cost after iteration 494: 0.015523
Cost after iteration 495: 0.015492
Cost after iteration 496: 0.015460
Cost after iteration 497: 0.015429
Cost after iteration 498: 0.015398
Cost after iteration 499: 0.015367
W = [[-7.94930555  7.68597905]]
b = [[-3.80585979]]
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">plot_decision_boundary</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">]</span>
    <span class="n">b</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]</span>

    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">colors</span><span class="o">.</span><span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">]));</span>
    
    <span class="n">x_line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]),</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">,:])</span><span class="o">*</span><span class="mf">1.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_line</span><span class="p">,</span> <span class="o">-</span> <span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">x_line</span> <span class="o">+</span> <span class="o">-</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">W</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
<span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<img alt="../../../_images/ca15a646adf15814e07f5d6169f99359017cfa1c7afc1702c65255b8ead8ef96.png" src="../../../_images/ca15a646adf15814e07f5d6169f99359017cfa1c7afc1702c65255b8ead8ef96.png" />
</div>
</details>
</div>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Using the learned parameters, predicts a class for each example in X</span>
<span class="sd">    </span>
<span class="sd">    Arguments:</span>
<span class="sd">    parameters -- python dictionary containing your parameters </span>
<span class="sd">    X -- input data of size (n_x, m)</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    predictions -- vector of predictions of our model (blue: False / red: True)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    
    <span class="c1"># Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">A</span> <span class="o">&gt;</span> <span class="mf">0.5</span>
    
    <span class="k">return</span> <span class="n">predictions</span>

<span class="n">X_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                   <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="n">Y_pred</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">X_pred</span><span class="p">,</span> <span class="n">parameters</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Coordinates (in the columns):</span><span class="se">\n</span><span class="si">{</span><span class="n">X_pred</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predictions:</span><span class="se">\n</span><span class="si">{</span><span class="n">Y_pred</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Coordinates (in the columns):
[[1 1 0 0]
 [0 1 0 1]]
Predictions:
[[False False False  True]]
</pre></div>
</div>
</div>
</details>
</div>
<p><a name='3'></a></p>
</section>
<section id="performance-on-a-larger-dataset">
<h2>3 - Performance on a Larger Dataset<a class="headerlink" href="#performance-on-a-larger-dataset" title="Link to this heading">#</a></h2>
<p>Construct a larger and more complex dataset with the function <code class="docutils literal notranslate"><span class="pre">make_blobs</span></code> from the <code class="docutils literal notranslate"><span class="pre">sklearn.datasets</span></code> library:</p>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dataset</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">samples</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span> 
                             <span class="n">centers</span><span class="o">=</span><span class="p">([</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mf">6.7</span><span class="p">,</span> <span class="mf">7.9</span><span class="p">]),</span> 
                             <span class="n">cluster_std</span><span class="o">=</span><span class="mf">1.4</span><span class="p">,</span>
                             <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">X_larger</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
<span class="n">Y_larger</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span><span class="n">n_samples</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_larger</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">X_larger</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">c</span><span class="o">=</span><span class="n">Y_larger</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">colors</span><span class="o">.</span><span class="n">ListedColormap</span><span class="p">([</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">]));</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<img alt="../../../_images/a272cfe5aaecff24363517c2206813b39ad609aa9477b36783aadb24fe8cbd72.png" src="../../../_images/a272cfe5aaecff24363517c2206813b39ad609aa9477b36783aadb24fe8cbd72.png" />
</div>
</details>
</div>
<p>And train your neural network for <span class="math notranslate nohighlight">\(600\)</span> iterations.</p>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">parameters_larger</span> <span class="o">=</span> <span class="n">nn_model</span><span class="p">(</span><span class="n">X_larger</span><span class="p">,</span> <span class="n">Y_larger</span><span class="p">,</span> <span class="n">num_iterations</span><span class="o">=</span><span class="mi">600</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">print_cost</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;W = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters_larger</span><span class="p">[</span><span class="s2">&quot;W&quot;</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;b = &quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">parameters_larger</span><span class="p">[</span><span class="s2">&quot;b&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cost after iteration 0: 0.715632
Cost after iteration 1: 0.619924
Cost after iteration 2: 0.598855
Cost after iteration 3: 0.595347
Cost after iteration 4: 0.591877
Cost after iteration 5: 0.588444
Cost after iteration 6: 0.585047
Cost after iteration 7: 0.581686
Cost after iteration 8: 0.578359
Cost after iteration 9: 0.575067
Cost after iteration 10: 0.571807
Cost after iteration 11: 0.568581
Cost after iteration 12: 0.565387
Cost after iteration 13: 0.562225
Cost after iteration 14: 0.559094
Cost after iteration 15: 0.555995
Cost after iteration 16: 0.552925
Cost after iteration 17: 0.549885
Cost after iteration 18: 0.546875
Cost after iteration 19: 0.543894
Cost after iteration 20: 0.540942
Cost after iteration 21: 0.538018
Cost after iteration 22: 0.535121
Cost after iteration 23: 0.532252
Cost after iteration 24: 0.529411
Cost after iteration 25: 0.526596
Cost after iteration 26: 0.523807
Cost after iteration 27: 0.521045
Cost after iteration 28: 0.518309
Cost after iteration 29: 0.515598
Cost after iteration 30: 0.512912
Cost after iteration 31: 0.510251
Cost after iteration 32: 0.507615
Cost after iteration 33: 0.505002
Cost after iteration 34: 0.502414
Cost after iteration 35: 0.499850
Cost after iteration 36: 0.497309
Cost after iteration 37: 0.494791
Cost after iteration 38: 0.492297
Cost after iteration 39: 0.489825
Cost after iteration 40: 0.487375
Cost after iteration 41: 0.484947
Cost after iteration 42: 0.482542
Cost after iteration 43: 0.480158
Cost after iteration 44: 0.477795
Cost after iteration 45: 0.475454
Cost after iteration 46: 0.473134
Cost after iteration 47: 0.470834
Cost after iteration 48: 0.468555
Cost after iteration 49: 0.466296
Cost after iteration 50: 0.464057
Cost after iteration 51: 0.461838
Cost after iteration 52: 0.459639
Cost after iteration 53: 0.457459
Cost after iteration 54: 0.455299
Cost after iteration 55: 0.453157
Cost after iteration 56: 0.451034
Cost after iteration 57: 0.448930
Cost after iteration 58: 0.446844
Cost after iteration 59: 0.444776
Cost after iteration 60: 0.442727
Cost after iteration 61: 0.440695
Cost after iteration 62: 0.438681
Cost after iteration 63: 0.436684
Cost after iteration 64: 0.434705
Cost after iteration 65: 0.432742
Cost after iteration 66: 0.430796
Cost after iteration 67: 0.428868
Cost after iteration 68: 0.426955
Cost after iteration 69: 0.425059
Cost after iteration 70: 0.423179
Cost after iteration 71: 0.421316
Cost after iteration 72: 0.419467
Cost after iteration 73: 0.417635
Cost after iteration 74: 0.415818
Cost after iteration 75: 0.414017
Cost after iteration 76: 0.412230
Cost after iteration 77: 0.410459
Cost after iteration 78: 0.408702
Cost after iteration 79: 0.406961
Cost after iteration 80: 0.405233
Cost after iteration 81: 0.403520
Cost after iteration 82: 0.401822
Cost after iteration 83: 0.400137
Cost after iteration 84: 0.398466
Cost after iteration 85: 0.396809
Cost after iteration 86: 0.395166
Cost after iteration 87: 0.393536
Cost after iteration 88: 0.391920
Cost after iteration 89: 0.390316
Cost after iteration 90: 0.388726
Cost after iteration 91: 0.387149
Cost after iteration 92: 0.385585
Cost after iteration 93: 0.384033
Cost after iteration 94: 0.382493
Cost after iteration 95: 0.380966
Cost after iteration 96: 0.379452
Cost after iteration 97: 0.377949
Cost after iteration 98: 0.376459
Cost after iteration 99: 0.374980
Cost after iteration 100: 0.373513
Cost after iteration 101: 0.372058
Cost after iteration 102: 0.370614
Cost after iteration 103: 0.369182
Cost after iteration 104: 0.367761
Cost after iteration 105: 0.366351
Cost after iteration 106: 0.364952
Cost after iteration 107: 0.363564
Cost after iteration 108: 0.362187
Cost after iteration 109: 0.360821
Cost after iteration 110: 0.359465
Cost after iteration 111: 0.358120
Cost after iteration 112: 0.356785
Cost after iteration 113: 0.355460
Cost after iteration 114: 0.354145
Cost after iteration 115: 0.352841
Cost after iteration 116: 0.351546
Cost after iteration 117: 0.350262
Cost after iteration 118: 0.348987
Cost after iteration 119: 0.347722
Cost after iteration 120: 0.346466
Cost after iteration 121: 0.345220
Cost after iteration 122: 0.343983
Cost after iteration 123: 0.342755
Cost after iteration 124: 0.341537
Cost after iteration 125: 0.340327
Cost after iteration 126: 0.339127
Cost after iteration 127: 0.337936
Cost after iteration 128: 0.336753
Cost after iteration 129: 0.335579
Cost after iteration 130: 0.334414
Cost after iteration 131: 0.333257
Cost after iteration 132: 0.332109
Cost after iteration 133: 0.330969
Cost after iteration 134: 0.329837
Cost after iteration 135: 0.328714
Cost after iteration 136: 0.327598
Cost after iteration 137: 0.326491
Cost after iteration 138: 0.325392
Cost after iteration 139: 0.324300
Cost after iteration 140: 0.323217
Cost after iteration 141: 0.322141
Cost after iteration 142: 0.321073
Cost after iteration 143: 0.320012
Cost after iteration 144: 0.318959
Cost after iteration 145: 0.317913
Cost after iteration 146: 0.316875
Cost after iteration 147: 0.315844
Cost after iteration 148: 0.314820
Cost after iteration 149: 0.313804
Cost after iteration 150: 0.312794
Cost after iteration 151: 0.311792
Cost after iteration 152: 0.310796
Cost after iteration 153: 0.309807
Cost after iteration 154: 0.308825
Cost after iteration 155: 0.307850
Cost after iteration 156: 0.306882
Cost after iteration 157: 0.305920
Cost after iteration 158: 0.304965
Cost after iteration 159: 0.304016
Cost after iteration 160: 0.303073
Cost after iteration 161: 0.302137
Cost after iteration 162: 0.301208
Cost after iteration 163: 0.300284
Cost after iteration 164: 0.299367
Cost after iteration 165: 0.298456
Cost after iteration 166: 0.297551
Cost after iteration 167: 0.296652
Cost after iteration 168: 0.295759
Cost after iteration 169: 0.294872
Cost after iteration 170: 0.293990
Cost after iteration 171: 0.293115
Cost after iteration 172: 0.292245
Cost after iteration 173: 0.291381
Cost after iteration 174: 0.290522
Cost after iteration 175: 0.289670
Cost after iteration 176: 0.288822
Cost after iteration 177: 0.287980
Cost after iteration 178: 0.287144
Cost after iteration 179: 0.286313
Cost after iteration 180: 0.285487
Cost after iteration 181: 0.284667
Cost after iteration 182: 0.283852
Cost after iteration 183: 0.283042
Cost after iteration 184: 0.282237
Cost after iteration 185: 0.281437
Cost after iteration 186: 0.280643
Cost after iteration 187: 0.279853
Cost after iteration 188: 0.279068
Cost after iteration 189: 0.278288
Cost after iteration 190: 0.277513
Cost after iteration 191: 0.276743
Cost after iteration 192: 0.275978
Cost after iteration 193: 0.275218
Cost after iteration 194: 0.274462
Cost after iteration 195: 0.273710
Cost after iteration 196: 0.272964
Cost after iteration 197: 0.272222
Cost after iteration 198: 0.271484
Cost after iteration 199: 0.270752
Cost after iteration 200: 0.270023
Cost after iteration 201: 0.269299
Cost after iteration 202: 0.268579
Cost after iteration 203: 0.267864
Cost after iteration 204: 0.267153
Cost after iteration 205: 0.266446
Cost after iteration 206: 0.265744
Cost after iteration 207: 0.265045
Cost after iteration 208: 0.264351
Cost after iteration 209: 0.263661
Cost after iteration 210: 0.262975
Cost after iteration 211: 0.262293
Cost after iteration 212: 0.261615
Cost after iteration 213: 0.260941
Cost after iteration 214: 0.260271
Cost after iteration 215: 0.259605
Cost after iteration 216: 0.258943
Cost after iteration 217: 0.258285
Cost after iteration 218: 0.257630
Cost after iteration 219: 0.256980
Cost after iteration 220: 0.256333
Cost after iteration 221: 0.255689
Cost after iteration 222: 0.255050
Cost after iteration 223: 0.254414
Cost after iteration 224: 0.253782
Cost after iteration 225: 0.253153
Cost after iteration 226: 0.252528
Cost after iteration 227: 0.251907
Cost after iteration 228: 0.251289
Cost after iteration 229: 0.250674
Cost after iteration 230: 0.250063
Cost after iteration 231: 0.249455
Cost after iteration 232: 0.248851
Cost after iteration 233: 0.248250
Cost after iteration 234: 0.247653
Cost after iteration 235: 0.247059
Cost after iteration 236: 0.246468
Cost after iteration 237: 0.245880
Cost after iteration 238: 0.245296
Cost after iteration 239: 0.244714
Cost after iteration 240: 0.244136
Cost after iteration 241: 0.243562
Cost after iteration 242: 0.242990
Cost after iteration 243: 0.242421
Cost after iteration 244: 0.241856
Cost after iteration 245: 0.241293
Cost after iteration 246: 0.240734
Cost after iteration 247: 0.240178
Cost after iteration 248: 0.239624
Cost after iteration 249: 0.239074
Cost after iteration 250: 0.238526
Cost after iteration 251: 0.237982
Cost after iteration 252: 0.237440
Cost after iteration 253: 0.236901
Cost after iteration 254: 0.236365
Cost after iteration 255: 0.235832
Cost after iteration 256: 0.235302
Cost after iteration 257: 0.234774
Cost after iteration 258: 0.234250
Cost after iteration 259: 0.233728
Cost after iteration 260: 0.233208
Cost after iteration 261: 0.232692
Cost after iteration 262: 0.232178
Cost after iteration 263: 0.231667
Cost after iteration 264: 0.231158
Cost after iteration 265: 0.230652
Cost after iteration 266: 0.230149
Cost after iteration 267: 0.229648
Cost after iteration 268: 0.229150
Cost after iteration 269: 0.228654
Cost after iteration 270: 0.228161
Cost after iteration 271: 0.227670
Cost after iteration 272: 0.227182
Cost after iteration 273: 0.226696
Cost after iteration 274: 0.226213
Cost after iteration 275: 0.225732
Cost after iteration 276: 0.225254
Cost after iteration 277: 0.224778
Cost after iteration 278: 0.224304
Cost after iteration 279: 0.223833
Cost after iteration 280: 0.223364
Cost after iteration 281: 0.222897
Cost after iteration 282: 0.222433
Cost after iteration 283: 0.221971
Cost after iteration 284: 0.221511
Cost after iteration 285: 0.221054
Cost after iteration 286: 0.220598
Cost after iteration 287: 0.220145
Cost after iteration 288: 0.219695
Cost after iteration 289: 0.219246
Cost after iteration 290: 0.218799
Cost after iteration 291: 0.218355
Cost after iteration 292: 0.217913
Cost after iteration 293: 0.217473
Cost after iteration 294: 0.217035
Cost after iteration 295: 0.216599
Cost after iteration 296: 0.216166
Cost after iteration 297: 0.215734
Cost after iteration 298: 0.215304
Cost after iteration 299: 0.214877
Cost after iteration 300: 0.214451
Cost after iteration 301: 0.214028
Cost after iteration 302: 0.213606
Cost after iteration 303: 0.213187
Cost after iteration 304: 0.212769
Cost after iteration 305: 0.212354
Cost after iteration 306: 0.211940
Cost after iteration 307: 0.211528
Cost after iteration 308: 0.211119
Cost after iteration 309: 0.210711
Cost after iteration 310: 0.210305
Cost after iteration 311: 0.209901
Cost after iteration 312: 0.209498
Cost after iteration 313: 0.209098
Cost after iteration 314: 0.208699
Cost after iteration 315: 0.208303
Cost after iteration 316: 0.207908
Cost after iteration 317: 0.207515
Cost after iteration 318: 0.207123
Cost after iteration 319: 0.206734
Cost after iteration 320: 0.206346
Cost after iteration 321: 0.205960
Cost after iteration 322: 0.205575
Cost after iteration 323: 0.205193
Cost after iteration 324: 0.204812
Cost after iteration 325: 0.204433
Cost after iteration 326: 0.204055
Cost after iteration 327: 0.203680
Cost after iteration 328: 0.203306
Cost after iteration 329: 0.202933
Cost after iteration 330: 0.202562
Cost after iteration 331: 0.202193
Cost after iteration 332: 0.201826
Cost after iteration 333: 0.201460
Cost after iteration 334: 0.201095
Cost after iteration 335: 0.200733
Cost after iteration 336: 0.200372
Cost after iteration 337: 0.200012
Cost after iteration 338: 0.199654
Cost after iteration 339: 0.199298
Cost after iteration 340: 0.198943
Cost after iteration 341: 0.198590
Cost after iteration 342: 0.198238
Cost after iteration 343: 0.197887
Cost after iteration 344: 0.197539
Cost after iteration 345: 0.197191
Cost after iteration 346: 0.196846
Cost after iteration 347: 0.196501
Cost after iteration 348: 0.196158
Cost after iteration 349: 0.195817
Cost after iteration 350: 0.195477
Cost after iteration 351: 0.195138
Cost after iteration 352: 0.194801
Cost after iteration 353: 0.194466
Cost after iteration 354: 0.194131
Cost after iteration 355: 0.193799
Cost after iteration 356: 0.193467
Cost after iteration 357: 0.193137
Cost after iteration 358: 0.192808
Cost after iteration 359: 0.192481
Cost after iteration 360: 0.192155
Cost after iteration 361: 0.191830
Cost after iteration 362: 0.191507
Cost after iteration 363: 0.191185
Cost after iteration 364: 0.190865
Cost after iteration 365: 0.190545
Cost after iteration 366: 0.190227
Cost after iteration 367: 0.189911
Cost after iteration 368: 0.189595
Cost after iteration 369: 0.189281
Cost after iteration 370: 0.188968
Cost after iteration 371: 0.188657
Cost after iteration 372: 0.188346
Cost after iteration 373: 0.188037
Cost after iteration 374: 0.187730
Cost after iteration 375: 0.187423
Cost after iteration 376: 0.187118
Cost after iteration 377: 0.186814
Cost after iteration 378: 0.186511
Cost after iteration 379: 0.186209
Cost after iteration 380: 0.185909
Cost after iteration 381: 0.185609
Cost after iteration 382: 0.185311
Cost after iteration 383: 0.185014
Cost after iteration 384: 0.184719
Cost after iteration 385: 0.184424
Cost after iteration 386: 0.184131
Cost after iteration 387: 0.183839
Cost after iteration 388: 0.183547
Cost after iteration 389: 0.183257
Cost after iteration 390: 0.182969
Cost after iteration 391: 0.182681
Cost after iteration 392: 0.182394
Cost after iteration 393: 0.182109
Cost after iteration 394: 0.181824
Cost after iteration 395: 0.181541
Cost after iteration 396: 0.181259
Cost after iteration 397: 0.180978
Cost after iteration 398: 0.180698
Cost after iteration 399: 0.180419
Cost after iteration 400: 0.180141
Cost after iteration 401: 0.179864
Cost after iteration 402: 0.179589
Cost after iteration 403: 0.179314
Cost after iteration 404: 0.179040
Cost after iteration 405: 0.178768
Cost after iteration 406: 0.178496
Cost after iteration 407: 0.178226
Cost after iteration 408: 0.177956
Cost after iteration 409: 0.177688
Cost after iteration 410: 0.177420
Cost after iteration 411: 0.177153
Cost after iteration 412: 0.176888
Cost after iteration 413: 0.176623
Cost after iteration 414: 0.176360
Cost after iteration 415: 0.176097
Cost after iteration 416: 0.175836
Cost after iteration 417: 0.175575
Cost after iteration 418: 0.175316
Cost after iteration 419: 0.175057
Cost after iteration 420: 0.174799
Cost after iteration 421: 0.174542
Cost after iteration 422: 0.174286
Cost after iteration 423: 0.174032
Cost after iteration 424: 0.173778
Cost after iteration 425: 0.173525
Cost after iteration 426: 0.173272
Cost after iteration 427: 0.173021
Cost after iteration 428: 0.172771
Cost after iteration 429: 0.172522
Cost after iteration 430: 0.172273
Cost after iteration 431: 0.172025
Cost after iteration 432: 0.171779
Cost after iteration 433: 0.171533
Cost after iteration 434: 0.171288
Cost after iteration 435: 0.171044
Cost after iteration 436: 0.170801
Cost after iteration 437: 0.170558
Cost after iteration 438: 0.170317
Cost after iteration 439: 0.170076
Cost after iteration 440: 0.169837
Cost after iteration 441: 0.169598
Cost after iteration 442: 0.169360
Cost after iteration 443: 0.169123
Cost after iteration 444: 0.168886
Cost after iteration 445: 0.168651
Cost after iteration 446: 0.168416
Cost after iteration 447: 0.168182
Cost after iteration 448: 0.167949
Cost after iteration 449: 0.167717
Cost after iteration 450: 0.167485
Cost after iteration 451: 0.167255
Cost after iteration 452: 0.167025
Cost after iteration 453: 0.166796
Cost after iteration 454: 0.166567
Cost after iteration 455: 0.166340
Cost after iteration 456: 0.166113
Cost after iteration 457: 0.165887
Cost after iteration 458: 0.165662
Cost after iteration 459: 0.165438
Cost after iteration 460: 0.165214
Cost after iteration 461: 0.164991
Cost after iteration 462: 0.164769
Cost after iteration 463: 0.164548
Cost after iteration 464: 0.164327
Cost after iteration 465: 0.164108
Cost after iteration 466: 0.163889
Cost after iteration 467: 0.163670
Cost after iteration 468: 0.163453
Cost after iteration 469: 0.163236
Cost after iteration 470: 0.163020
Cost after iteration 471: 0.162804
Cost after iteration 472: 0.162590
Cost after iteration 473: 0.162376
Cost after iteration 474: 0.162162
Cost after iteration 475: 0.161950
Cost after iteration 476: 0.161738
Cost after iteration 477: 0.161527
Cost after iteration 478: 0.161316
Cost after iteration 479: 0.161107
Cost after iteration 480: 0.160898
Cost after iteration 481: 0.160689
Cost after iteration 482: 0.160482
Cost after iteration 483: 0.160275
Cost after iteration 484: 0.160068
Cost after iteration 485: 0.159863
Cost after iteration 486: 0.159658
Cost after iteration 487: 0.159453
Cost after iteration 488: 0.159250
Cost after iteration 489: 0.159047
Cost after iteration 490: 0.158845
Cost after iteration 491: 0.158643
Cost after iteration 492: 0.158442
Cost after iteration 493: 0.158242
Cost after iteration 494: 0.158042
Cost after iteration 495: 0.157843
Cost after iteration 496: 0.157644
Cost after iteration 497: 0.157447
Cost after iteration 498: 0.157249
Cost after iteration 499: 0.157053
Cost after iteration 500: 0.156857
Cost after iteration 501: 0.156662
Cost after iteration 502: 0.156467
Cost after iteration 503: 0.156273
Cost after iteration 504: 0.156080
Cost after iteration 505: 0.155887
Cost after iteration 506: 0.155695
Cost after iteration 507: 0.155503
Cost after iteration 508: 0.155312
Cost after iteration 509: 0.155122
Cost after iteration 510: 0.154932
Cost after iteration 511: 0.154743
Cost after iteration 512: 0.154554
Cost after iteration 513: 0.154366
Cost after iteration 514: 0.154179
Cost after iteration 515: 0.153992
Cost after iteration 516: 0.153806
Cost after iteration 517: 0.153620
Cost after iteration 518: 0.153435
Cost after iteration 519: 0.153250
Cost after iteration 520: 0.153066
Cost after iteration 521: 0.152883
Cost after iteration 522: 0.152700
Cost after iteration 523: 0.152518
Cost after iteration 524: 0.152336
Cost after iteration 525: 0.152155
Cost after iteration 526: 0.151974
Cost after iteration 527: 0.151794
Cost after iteration 528: 0.151615
Cost after iteration 529: 0.151436
Cost after iteration 530: 0.151257
Cost after iteration 531: 0.151079
Cost after iteration 532: 0.150902
Cost after iteration 533: 0.150725
Cost after iteration 534: 0.150549
Cost after iteration 535: 0.150373
Cost after iteration 536: 0.150198
Cost after iteration 537: 0.150023
Cost after iteration 538: 0.149849
Cost after iteration 539: 0.149676
Cost after iteration 540: 0.149502
Cost after iteration 541: 0.149330
Cost after iteration 542: 0.149158
Cost after iteration 543: 0.148986
Cost after iteration 544: 0.148815
Cost after iteration 545: 0.148644
Cost after iteration 546: 0.148474
Cost after iteration 547: 0.148305
Cost after iteration 548: 0.148136
Cost after iteration 549: 0.147967
Cost after iteration 550: 0.147799
Cost after iteration 551: 0.147632
Cost after iteration 552: 0.147465
Cost after iteration 553: 0.147298
Cost after iteration 554: 0.147132
Cost after iteration 555: 0.146966
Cost after iteration 556: 0.146801
Cost after iteration 557: 0.146636
Cost after iteration 558: 0.146472
Cost after iteration 559: 0.146309
Cost after iteration 560: 0.146145
Cost after iteration 561: 0.145983
Cost after iteration 562: 0.145820
Cost after iteration 563: 0.145658
Cost after iteration 564: 0.145497
Cost after iteration 565: 0.145336
Cost after iteration 566: 0.145176
Cost after iteration 567: 0.145016
Cost after iteration 568: 0.144856
Cost after iteration 569: 0.144697
Cost after iteration 570: 0.144539
Cost after iteration 571: 0.144380
Cost after iteration 572: 0.144223
Cost after iteration 573: 0.144066
Cost after iteration 574: 0.143909
Cost after iteration 575: 0.143752
Cost after iteration 576: 0.143596
Cost after iteration 577: 0.143441
Cost after iteration 578: 0.143286
Cost after iteration 579: 0.143131
Cost after iteration 580: 0.142977
Cost after iteration 581: 0.142823
Cost after iteration 582: 0.142670
Cost after iteration 583: 0.142517
Cost after iteration 584: 0.142365
Cost after iteration 585: 0.142213
Cost after iteration 586: 0.142061
Cost after iteration 587: 0.141910
Cost after iteration 588: 0.141759
Cost after iteration 589: 0.141609
Cost after iteration 590: 0.141459
Cost after iteration 591: 0.141309
Cost after iteration 592: 0.141160
Cost after iteration 593: 0.141011
Cost after iteration 594: 0.140863
Cost after iteration 595: 0.140715
Cost after iteration 596: 0.140568
Cost after iteration 597: 0.140421
Cost after iteration 598: 0.140274
Cost after iteration 599: 0.140128
W = [[0.49908216 0.51641999]]
b = [[-4.69274864]]
</pre></div>
</div>
</div>
</details>
</div>
<p>Plot the decision boundary:</p>
<div class="cell tag_hide-output tag_scroll-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_decision_boundary</span><span class="p">(</span><span class="n">X_larger</span><span class="p">,</span> <span class="n">Y_larger</span><span class="p">,</span> <span class="n">parameters_larger</span><span class="p">)</span>
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<img alt="../../../_images/b0023942cb9fad7a7635ef2663243c285400b8d6352fc339de3da274f7c85f85.png" src="../../../_images/b0023942cb9fad7a7635ef2663243c285400b8d6352fc339de3da274f7c85f85.png" />
</div>
</details>
</div>
</section>
</section>


                </article>
              
              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../index.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Classification</p>
      </div>
    </a>
    <a class="right-next"
       href="../../regression/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Regression</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
<div
    id="pst-page-navigation-heading-2"
    class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> On this page
  </div>
  <nav class="bd-toc-nav page-toc" aria-labelledby="pst-page-navigation-heading-2">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#packages">Packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#single-perceptron-neural-network-with-activation-function">1 - Single Perceptron Neural Network with Activation Function</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-network-structure">1.1 - Neural Network Structure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset">- Dataset</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#define-activation-function">- Define Activation Function</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation-of-the-neural-network-model">2 - Implementation of the Neural Network Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#performance-on-a-larger-dataset">3 - Performance on a Larger Dataset</a></li>
</ul>
  </nav></div>

  <div class="sidebar-secondary-item">

  <div class="tocsection sourcelink">
    <a href="../../../_sources/notebooks/classification/classification_with_single_perceptron/classification_with_single_perceptron.ipynb.txt">
      <i class="fa-solid fa-file-lines"></i> Show Source
    </a>
  </div>
</div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
          </footer>
        
      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
<div class="bd-footer__inner bd-page-width">
  
    <div class="footer-items__start">
      
        <div class="footer-item">

  <p class="copyright">
    
      Â© Copyright 2025, cornel @ AI Learning Labs.
      <br/>
    
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__center">
      
        <div class="footer-item">

  <p class="sphinx-version">
    Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.7.
    <br/>
  </p>
</div>
      
    </div>
  
  
    <div class="footer-items__end">
      
        <div class="footer-item">
<p class="theme-version">
  Built with the <a href="https://pydata-sphinx-theme.readthedocs.io/en/stable/index.html">PyData Sphinx Theme</a> 0.15.4.
</p></div>
      
    </div>
  
</div>

  </footer>
  </body>
</html>